{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5a85c-928a-4e7f-b90e-8a20ed61de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "import pygame\n",
    "from gtts import gTTS\n",
    "import speech_recognition as sr\n",
    "import tempfile\n",
    "import torch\n",
    "import datetime                                                                                 \n",
    "import requests\n",
    "import random  # Import for random jokes/quotes\n",
    "import time  # Import for reminders\n",
    "\n",
    "# Suppress FutureWarning for tokenization spaces\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers.tokenization_utils_base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4ca2bf-a3c6-4069-8584-f0aaf22c8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"Qwen/Qwen2.5-1.5B-Instruct\" # Larger model with the same functional capabilities facebook/blenderbot-3B # Qwen/Qwen2.5-1.5B-Instruct # facebook/blenderbot-400M-distill\n",
    "# tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
    "# model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n",
    "WEATHER_API_KEY = '6375f15162952d140f9908db1d7ffb99'\n",
    "\n",
    "\n",
    "\n",
    "# Load the Qwen tokenizer and model\n",
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the Qwen tokenizer and model\n",
    "# model_name = \"Qwen-7B\"  \n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# # Conditional input prompt\n",
    "# # Example: Generating a story about a futuristic bike\n",
    "# prompt = (\n",
    "#     \"Write a short story about an electric bike that can talk to its rider, \"\n",
    "#     \"helping them navigate through a futuristic city.\"\n",
    "# )\n",
    "\n",
    "# # Tokenize the conditional input\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# # Generate output based on the condition\n",
    "# output = model.generate(\n",
    "#     inputs[\"input_ids\"],\n",
    "#     max_length=150,            # Limit the length of the generated text\n",
    "#     num_return_sequences=1,    # Number of sequences to generate\n",
    "#     temperature=0.7,           # Sampling temperature (lower for more focused output)\n",
    "#     top_k=50,                  # Top-k sampling for more diverse results\n",
    "#     top_p=0.95,                # Nucleus sampling for coherent text\n",
    "#     repetition_penalty=1.2,    # Penalize repeated tokens to avoid loops\n",
    "#     early_stopping=True        # Stop generating when a complete result is found\n",
    "# )\n",
    "\n",
    "# # Decode and print the generated output\n",
    "# output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "# print(\"Generated Conditional Output:\")\n",
    "# print(output_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb4630d-1ce2-4fc0-bfca-eb3eb7e0e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_microphone():\n",
    "    mic_index = 2  # Automatically select microphone index 2\n",
    "    print(f\"Using microphone with index: {mic_index}\")\n",
    "    return mic_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65a538d-4a4a-42a2-86ba-5a5ffce4527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_speech(mic_index):\n",
    "    recognizer = sr.Recognizer()\n",
    "    recognizer.energy_threshold = 300  # Lower energy threshold for faster detection\n",
    "    mic = sr.Microphone(device_index=mic_index)\n",
    "    \n",
    "    with mic as source:\n",
    "        print(\"Listening for your query...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        \n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)\n",
    "\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"Listening timed out, please speak again.\")\n",
    "            return None  \n",
    "\n",
    "    try:\n",
    "        user_input = recognizer.recognize_google(audio)\n",
    "        print(f\"User said: {user_input}\")  \n",
    "        return user_input\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I could not understand the audio.\")\n",
    "        return None\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Error with the Google Speech Recognition service; {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "547cf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama-3.2-11B-Vision-Instruct(model output generation and the implementation)\n",
    "\n",
    "# # Step 1: Import necessary libraries\n",
    "# from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "# import torch\n",
    "\n",
    "# # Step 2: Use a publicly available lighter LLaMA model to prevent kernel crashes\n",
    "# model_name = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"  # Lighter LLaMA model\n",
    "\n",
    "# # Step 3: Load the tokenizer and model from Hugging Face, without legacy issues\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(model_name, legacy=False)  # Set legacy=False to avoid warning\n",
    "# model = LlamaForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# # Step 4: Define function to generate response using the LLaMA model\n",
    "# def generate_response(user_input):\n",
    "#     inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, padding=True, max_length=150, padding_token=eos_token)\n",
    "#   attention_mask = inputs['attention_mask']\n",
    "    \n",
    "#     # Generate response with attention mask\n",
    "#     output = model.generate(inputs.input_ids, attention_mask=attention_mask, max_length=150)\n",
    "#     bot_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "#     return bot_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66514fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dialogpt for Conversational as the key task and its end to end implementation\n",
    "# def generate_response(input_text):\n",
    "#     # Load a pre-trained conversational model from Hugging Face\n",
    "#     conversation_pipeline = pipeline(\"conversational\", model=\"microsoft/DialoGPT-medium\")\n",
    "    \n",
    "#     if input_text.strip() == \"\":\n",
    "#         return \"I couldn't understand you. Could you please repeat?\"\n",
    "    \n",
    "#     response = conversation_pipeline(input_text)\n",
    "#     generated_response = response[0]['generated_text']\n",
    "#     print(f\"Amigo said: {generated_response}\")\n",
    "    \n",
    "#     return generated_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55fa5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Blenderbot Large model(facebook/blenderbot-3B) end to end implementation for both text generation and conversational\n",
    "\n",
    "# # Track conversational context\n",
    "# conversation_history = []\n",
    "\n",
    "# def generate_response(user_input):\n",
    "#     model_name = \"facebook/blenderbot-3B\"  # Switched to a larger, more capable model\n",
    "#     tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
    "#     model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n",
    "    \n",
    "#     # Add user input to conversation history\n",
    "#     conversation_history.append(user_input)\n",
    "    \n",
    "#     # Join conversation history to provide context\n",
    "#     conversation_context = \" \".join(conversation_history[-5:])  # Keeping the last 5 exchanges\n",
    "    \n",
    "#     # Adjust parameters for better logic and factual accuracy\n",
    "#     inputs = tokenizer(conversation_context, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "#     reply_ids = model.generate(\n",
    "#         inputs['input_ids'],\n",
    "#         max_length=512, \n",
    "#         pad_token_id=tokenizer.eos_token_id,\n",
    "#         temperature=0.7,  # Lower temperature for more logical responses\n",
    "#         num_beams=5,  # Beam search for more precise responses\n",
    "#         no_repeat_ngram_size=2  # Avoid repetition\n",
    "#     )\n",
    "    \n",
    "#     bot_response = tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "#     # Add bot response to the conversation history\n",
    "#     conversation_history.append(bot_response)\n",
    "    \n",
    "#     return bot_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a5cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lighter or more distilled(optimized version) dialogpt-medium end-to-end implementation for faster response time(reduced latency and inference)\n",
    "\n",
    "# def generate_response(input_text):\n",
    "#     Load a pre-trained conversational model from Hugging Face\n",
    "#     conversation_pipeline = pipeline(\"conversational\", model=\"microsoft/DialoGPT-medium\")\n",
    "    \n",
    "#     if input_text.strip() == \"\":\n",
    "#         return \"I couldn't understand you. Could you please repeat?\"\n",
    "    \n",
    "#     response = conversation_pipeline(input_text)\n",
    "#     generated_response = response[0]['generated_text']\n",
    "#     print(f\"Amigo said: {generated_response}\")\n",
    "    \n",
    "#     return generated_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915c49f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lighter and distilled conversational model end-to-end implementation\n",
    "# # Load the DistilGPT model and tokenizer\n",
    "# model_name = \"distilgpt2\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# # Add padding token\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a681b6b5-8b91-4b84-b522-fdd399cc7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_time_date_queries(user_input):\n",
    "    if \"time\" in user_input:\n",
    "        current_time = datetime.datetime.now().strftime(\"%I:%M %p\")\n",
    "        return f\" {current_time}.\"\n",
    "    elif \"date\" in user_input or \"today\" in user_input:\n",
    "        current_date = datetime.datetime.now().strftime(\"%A, %B %d, %Y\")\n",
    "        return f\" {current_date}.\"\n",
    "    elif \"location\" in user_input or \"where am i\" in user_input:\n",
    "        return get_current_location()  \n",
    "    elif \"weather\" in user_input or \"weather in my current location\" in user_input:\n",
    "        return get_current_weather()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_reminder(time_str, message_str):\n",
    "    global reminders\n",
    "    reminders_list = message_str.split('and')\n",
    "    \n",
    "    for reminder_message in reminders_list:\n",
    "        reminder_message = reminder_message.strip()  \n",
    "        if reminder_message:\n",
    "            formatted_reminder = f\"'{reminder_message}' at {time_str}\"  \n",
    "            reminders.append(formatted_reminder)\n",
    "    \n",
    "    return f\"Added {len(reminders_list)} reminder(s): {', '.join([f'{msg.strip()} at {time_str}' for msg in reminders_list])}.\"\n",
    "\n",
    "def list_reminders():\n",
    "    if not reminders:\n",
    "        return \"You have no reminders set.\"\n",
    "    \n",
    "    reminder_str = ', '.join(reminders)\n",
    "    return f\"Your reminders are: {reminder_str}.\"\n",
    "\n",
    "def delete_all_reminders():\n",
    "    global reminders\n",
    "    reminders.clear()\n",
    "    return \"All reminders have been deleted.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ec33a6-7f3f-4f38-a5c5-0adf925e9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_location():\n",
    "    try:\n",
    "        response = requests.get(\"http://ip-api.com/json\")\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] == 'success':\n",
    "            city = data.get('city', 'unknown city')\n",
    "            region = data.get('regionName', 'unknown region')\n",
    "            country = data.get('country', 'unknown country')\n",
    "            return f\"You are currently in {city}, {region}, {country}.\"\n",
    "        else:\n",
    "            return \"Sorry, I could not determine your location.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching location: {str(e)}\"\n",
    "\n",
    "def get_current_weather():\n",
    "    location = get_current_location()\n",
    "    if \"in\" in location:\n",
    "        city = location.split(\"in \")[1].split(\",\")[0]\n",
    "        try:\n",
    "            weather_url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={WEATHER_API_KEY}&units=metric\"\n",
    "            response = requests.get(weather_url)\n",
    "            data = response.json()\n",
    "            if data['cod'] == 200:\n",
    "                weather_description = data['weather'][0]['description']\n",
    "                temperature = data['main']['temp']\n",
    "                return f\"The current weather in {city} is {weather_description} with a temperature of {temperature}°C.\"\n",
    "            else:\n",
    "                return \"Sorry, I couldn't get the weather information.\"\n",
    "        except Exception:\n",
    "            return \"Error fetching weather.\"\n",
    "    else:\n",
    "        return \"I couldn't determine the location for weather.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9afdce15-bcc2-4d27-9917-13cf52868796",
   "metadata": {},
   "outputs": [],
   "source": [
    "reminders=[];\n",
    "def add_reminder(time_str, message_str):\n",
    "    global reminders\n",
    "    reminders_list = message_str.split('and')\n",
    "    \n",
    "    for reminder_message in reminders_list:\n",
    "        reminder_message = reminder_message.strip()  \n",
    "        if reminder_message:\n",
    "            formatted_reminder = f\"'{reminder_message}' at {time_str}\"  \n",
    "            reminders.append(formatted_reminder)\n",
    "    \n",
    "    return f\"Added {len(reminders_list)} reminder(s): {', '.join([f'{msg.strip()} at {time_str}' for msg in reminders_list])}.\"\n",
    "\n",
    "def list_reminders():\n",
    "    if not reminders:\n",
    "        return \"You have no reminders set.\"\n",
    "    \n",
    "    reminder_str = ', '.join(reminders)\n",
    "    return f\"Your reminders are: {reminder_str}.\"\n",
    "\n",
    "def delete_all_reminders():\n",
    "    global reminders\n",
    "    reminders.clear()\n",
    "    return \"All reminders have been deleted.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93331161-f01c-42f6-9964-4980bf778834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_reminders():\n",
    "    current_time = datetime.datetime.now().strftime(\"%H:%M\")\n",
    "    reminders_to_return = []\n",
    "    for reminder in reminders:\n",
    "        if reminder['time'] == current_time:\n",
    "            reminders_to_return.append(reminder['message'])\n",
    "    return reminders_to_return if reminders_to_return else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f005b1f-a995-480f-94b3-d1056c69b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_calculator_query(user_input):\n",
    "    try:\n",
    "        expression = user_input.lower().replace('calculate', '').strip()\n",
    "        result = eval(expression)\n",
    "        return f\"The result is {result}.\"\n",
    "    except Exception as e:\n",
    "        return \"There was an error with your calculation.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96755889-321d-442f-a6ab-1d9c26449ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes = [\n",
    "    \"Parallel lines have so much in common. Too bad they’ll never meet.\"\n",
    "    \"Why don't scientists trust atoms? Because they make up everything!\",\n",
    "    \"A snowman crossed with a vampire? Frostbite!\",\n",
    "    \"Did you hear about the scarecrow who won an award? Apparently, he was outstanding in his field!\",\n",
    "    \"Someone’s wife was drawing her eyebrows too high. She looked really surprised!\",\n",
    "    \"What’s orange and sounds like a parrot? A carrot!\",\n",
    "    \"Skeletons never fight each other. They just don’t have the guts.\",\n",
    "    \"Giving Elsa a balloon is a bad idea. She’ll just let it go!\",\n",
    "    \"Parallel lines have so much in common. Too bad they’ll never meet.\",\n",
    "    \"Some couples avoid the gym. Guess some relationships just don’t work out.\",\n",
    "    \"The cheese factory explosion? Nothing left but de-brie.\",\n",
    "    \"A musician used to play piano by ear but now uses hands. Much easier.\",\n",
    "    \"Ever see a bicycle fall over? It was two-tired!\",\n",
    "    \"Someone beat their addiction to the hokey pokey by turning themselves around.\",\n",
    "    \"If a nose were 12 inches long, it would be a foot!\",\n",
    "    \"Did you hear about the kidnapping at the playground? They woke up!\",\n",
    "    \"The bank robber got caught after he went camping. Apparently, he stole some tents.\",\n",
    "    \"A steak went to the party, but nobody wanted it there. Too rare.\",\n",
    "    \"The elevator asked for a promotion. It thought it was due for a lift.\",\n",
    "    \"Why did the computer break up with the internet? Too many connections!\",\n",
    "    \"A sandwich tried to make friends at the bar, but the bartender told it, 'We don’t serve food here.'\",\n",
    "    \"The calendar was so popular... it had a lot of dates!\",\n",
    "    \"Why did the golfer bring an extra pair of pants? In case of a hole-in-one!\"\n",
    "   \"A guy’s bank called him to say his balance was outstanding. Turns out, they meant his account was empty!\",\n",
    "    \"A scarecrow went on a date. Apparently, he was outstanding in his field.\",\n",
    "    \"He tried to make a belt out of watches. Total waste of time.\",\n",
    "    \"Did you hear about the coffee shop? It’s now offering espresso yourself classes!\",\n",
    "    \"A chicken’s dream job? Working in the egg-sport industry.\",\n",
    "    \"When she asked the calendar out, he said he was already booked.\",\n",
    "    \"The ocean waved at everyone. Typical, it’s always full of itself.\",\n",
    "    \"The bakery opened a new branch. Guess you could say business is on the rise.\",\n",
    "    \"Saw a documentary on beavers. Best dam movie ever!\",\n",
    "    \"Someone tried to catch some fog yesterday. Missed it.\",\n",
    "    \"Two Wi-Fi signals got married. The reception was excellent.\",\n",
    "    \"A cucumber walked into a bar and got pickled.\",\n",
    "    \"If two wrongs don’t make a right, why do two Wrights make an airplane?\",\n",
    "    \"Reading a book on anti-gravity? Hard to put down!\",\n",
    "    \"The airport called—it said planes are running late because they’re grounded.\",\n",
    "    \"The shovel was voted the most groundbreaking invention.\",\n",
    "    \"A termite walks into a bar and asks, 'Is the bartender here?'\",\n",
    "    \"A tortilla’s dream job? Well, it’s on a roll.\",\n",
    "    \"A guy gave all his dead batteries away—free of charge.\",\n",
    "    \"Someone stole his Microsoft Office license. He said he’d Excel in finding them.\",\n",
    "    \"That kleptomaniac who stole my coffee? Really mugs me off.\",\n",
    "    \"A comedian found his biggest fans in the attic—just a bunch of old ceiling fans!\",\n",
    "    \"A guy broke his arm trying to catch a baseball. Guess it wasn’t his lucky catch!\",\n",
    "    \"The butcher brought his cow to work... talk about a rare situation!\"\n",
    "    \"I was going to tell you a joke about a broken pencil, but it’s pointless.\"\n",
    "]\n",
    "\n",
    "def tell_joke():\n",
    "    if jokes:\n",
    "        return jokes.pop(0)\n",
    "    else:\n",
    "        return \"I’ve run out of jokes!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4e29fa4-5e21-4c0d-b4ef-ccb8f1a278f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_response(text):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio_file:\n",
    "        tts.save(temp_audio_file.name)\n",
    "        temp_file_path = temp_audio_file.name\n",
    "    pygame.mixer.init()\n",
    "    try:\n",
    "        pygame.mixer.music.load(temp_file_path)\n",
    "        pygame.mixer.music.play()\n",
    "\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.wait(50)  # Check every 50ms for faster termination\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing audio: {e}\")\n",
    "    finally:\n",
    "        pygame.mixer.quit()\n",
    "        if os.path.exists(temp_file_path):\n",
    "            os.remove(temp_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12840091-ecdc-426b-962c-33b78db96ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  # Import for random fillers\n",
    "\n",
    "# Define fillers for different types of responses\n",
    "fillers = {\n",
    "    'greeting': [\n",
    "        \"Hey there, let's dive into this!\",\n",
    "        \"Oh, you're asking about that? Let me tell you!\",\n",
    "        \"Alright, here we go! Here's what I think...\",\n",
    "        \"Hmm, interesting question! Let me check that for you.\"\n",
    "    ],\n",
    "    'time': [\n",
    "        \"Tick-tock! It's Time to check the clock... it's...\",\n",
    "        \"Let's check the time! It's...\",\n",
    "\n",
    "    ],\n",
    "    'date': [\n",
    "        \"Let me check the calendar... Today is...\",\n",
    "        \"It’s... just another fabulous day! The date is...\",\n",
    "        \"Hold on, let me dig into the calendar... Today is...\"\n",
    "    ],\n",
    "    'location': [\n",
    "        \"I am trotting the globe to see where you are...\",\n",
    "        \"Aha, I see where you are! You are in...\",\n",
    "        \"Let me see where you are...\",\n",
    "    ],\n",
    "    'weather': [\n",
    "        \"Checking the skies for you right now...\",\n",
    "        \"Let me see what the weather gods have to say... It's...\",\n",
    "        \n",
    "    ],\n",
    "    \n",
    "    'joke': [\n",
    "        \"Ready for a laugh? Here’s a joke for you...\",\n",
    "        \"I’ve got a funny one for you...\",\n",
    "        \"I’ve got something funny to share, check this out...\"\n",
    "    ],\n",
    "     'general': [\n",
    "        \"Sure, let me check.\",\n",
    "        \"Hmm, let me think.\",\n",
    "        \"Just a moment...\",\n",
    "        \"Sure,\",\n",
    "\n",
    "    ],\n",
    "    'name': [\n",
    "        \"Oh, you're curious about me? Well, I'm Amigo, your loyal conversational companion!\",\n",
    "        \"Nice to meet you! I’m Amigo, always here to assist.\",\n",
    "        \"Ah, you're wondering who I am? I’m Amigo, I’m here to chat and help out whenever you need...Cheers to life\",\n",
    "        \"You can call me Amigo! I’m here to chat and help out whenever you need.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def get_filler(query_type):\n",
    "    # Pick a random filler from the appropriate category\n",
    "    return random.choice(fillers.get(query_type, fillers['general']))\n",
    "\n",
    "def generate_response(user_input):\n",
    "    user_input = user_input.lower()\n",
    "\n",
    "    # Handle name-related queries with engaging fillers\n",
    "    if \"what is your name\" in user_input or \"who are you\" in user_input or \"what's your name\" in user_input:\n",
    "        return get_filler('name') \n",
    "    # Handle reminders\n",
    "    if \"reminder\" in user_input:\n",
    "        if \"set\" in user_input:\n",
    "            try:\n",
    "                parts = user_input.split(\"for\")\n",
    "                time = parts[1].split(\"to\")[0].strip() if len(parts) > 1 else \"\"\n",
    "                messages = parts[1].split(\"to\")[1].strip() if len(parts) > 1 else \"\"\n",
    "\n",
    "                if time and messages:\n",
    "                    return get_filler('reminder') + add_reminder(time, messages)\n",
    "                else:\n",
    "                    return get_filler('general') + \" Please specify the reminder time and message correctly.\"\n",
    "            except:\n",
    "                return get_filler('general') + \" Please specify the reminder time and message correctly.\"\n",
    "        elif \"list\" in user_input:\n",
    "            return get_filler('reminder') + list_reminders()\n",
    "        elif \"delete all\" in user_input or \"remove all\" in user_input:\n",
    "            return get_filler('general') + delete_all_reminders()\n",
    "    \n",
    "    # Check reminders before generating response\n",
    "    reminder_notifications = check_reminders()\n",
    "    if reminder_notifications:\n",
    "        return get_filler('reminder') + \" You have the following reminders: \" + ', '.join(reminder_notifications)\n",
    "\n",
    "    # Handle calculator queries\n",
    "    if \"calculate\" in user_input:\n",
    "        return get_filler('general') + handle_calculator_query(user_input)\n",
    "\n",
    "    # Handle jokes\n",
    "    if \"joke\" in user_input:\n",
    "        return get_filler('joke') + tell_joke()\n",
    "\n",
    "    # Handle time and date queries\n",
    "    time_date_response = handle_time_date_queries(user_input)\n",
    "    if time_date_response:\n",
    "        if \"time\" in user_input:\n",
    "            return get_filler('time') + time_date_response\n",
    "        elif \"date\" in user_input or \"today\" in user_input:\n",
    "            return get_filler('date') + time_date_response\n",
    "\n",
    "    # Handle weather query\n",
    "    if \"weather\" in user_input or \"forecast\" in user_input:\n",
    "        return get_filler('weather') + get_current_weather()\n",
    "\n",
    "    # Handle location queries\n",
    "    if \"location\" in user_input or \"where am i\" in user_input:\n",
    "        return get_filler('location') + get_current_location()\n",
    "\n",
    "    # Tokenize user input\n",
    "    inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, max_length=150)\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    if 'attention_mask' not in inputs:\n",
    "        inputs['attention_mask'] = torch.ones_like(inputs['input_ids'])\n",
    "    \n",
    "    reply_ids = model.generate(inputs['input_ids'], max_length=150, pad_token_id=tokenizer.eos_token_id)\n",
    "    bot_response = tokenizer.decode(reply_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    \n",
    "    return get_filler('general') + bot_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a1795b2-66ee-462e-8f93-d4ed5d3b8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_for_wake_word(mic_index):\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone(device_index=mic_index)\n",
    "\n",
    "    print(\"Waiting for wake word 'Hey Amigo'...\")\n",
    "    while True:\n",
    "        with mic as source:\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "            audio = recognizer.listen(source)\n",
    "            \n",
    "        try:\n",
    "            user_input = recognizer.recognize_google(audio)\n",
    "            if \"hey amigo\" in user_input.lower():\n",
    "                print(\"Wake word detected!\")\n",
    "                return True\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Error with the Google Speech Recognition service: {e}\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11ca8ec4-da8b-4cf9-9768-d7177ad59606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amigo_conversational_companion():\n",
    "    mic_index = select_microphone()\n",
    "\n",
    "    if listen_for_wake_word(mic_index):\n",
    "        greeting = \"Hi Hello Namaskara, How can I assist you today?\"\n",
    "        print(f\"Amigo: {greeting}\")\n",
    "        speak_response(greeting)\n",
    "\n",
    "        while True:\n",
    "            user_input = capture_speech(mic_index)\n",
    "            if user_input is None:\n",
    "                continue\n",
    "\n",
    "            if \"exit\" in user_input.lower() or \"goodbye\" in user_input.lower():\n",
    "                farewell_message = \"Goodbye, have a nice day!\"\n",
    "                print(f\"Amigo: {farewell_message}\")\n",
    "                speak_response(farewell_message)\n",
    "                break\n",
    "\n",
    "            bot_response = generate_response(user_input)\n",
    "            print(f\"Amigo: {bot_response}\")\n",
    "            speak_response(bot_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31755df2-4065-494e-9564-86e709395ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    amigo_conversational_companion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191dd77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce62cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ebbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
