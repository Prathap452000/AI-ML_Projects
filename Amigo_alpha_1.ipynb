{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1bd15d-50fb-4f1d-9da9-3e5b5a1ab7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration # type: ignore\n",
    "import os\n",
    "import pygame # type: ignore\n",
    "from gtts import gTTS # type: ignore\n",
    "from time import sleep\n",
    "import speech_recognition as sr # type: ignore\n",
    "import tempfile\n",
    "import datetime  # New import for date and time\n",
    "\n",
    "# Suppress FutureWarning for tokenization spaces\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers.tokenization_utils_base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385f157-9243-40bd-a181-e6169cb3c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer globally to avoid reloading every time\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff22b0-abee-4b65-b77b-062bdfdd2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_speech(mic_index):\n",
    "    recognizer = sr.Recognizer()\n",
    "    recognizer.energy_threshold = 300  # Lower energy threshold for faster detection\n",
    "    mic = sr.Microphone(device_index=mic_index)\n",
    "    \n",
    "    with mic as source:\n",
    "        print(\"Listening for your query...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)  # Optimized ambient noise detection\n",
    "        \n",
    "        try:\n",
    "            # Listen with optimized timeout and phrase time limit\n",
    "            audio = recognizer.listen(source, timeout=5, phrase_time_limit=6)  # Slightly reduced timeout\n",
    "\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"Listening timed out, please speak again.\")\n",
    "            return None  # Return None if timeout occurs\n",
    "\n",
    "    try:\n",
    "        user_input = recognizer.recognize_google(audio)\n",
    "        print(f\"User said: {user_input}\")  # Display user input\n",
    "        return user_input\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I could not understand the audio.\")\n",
    "        return None\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Error with the Google Speech Recognition service; {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ceba7b-0ffb-45ed-9b80-776f292e33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_time_date_queries(user_input):\n",
    "    if \"time\" in user_input:\n",
    "        current_time = datetime.datetime.now().strftime(\"%I:%M %p\")\n",
    "        return f\"The current time is {current_time}.\"\n",
    "    elif \"date\" in user_input or \"today\" in user_input:\n",
    "        current_date = datetime.datetime.now().strftime(\"%A, %B %d, %Y\")\n",
    "        return f\"Today is {current_date}.\"\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a9f55a-ff70-4312-a2a7-f02fbea1cfe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mic_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Removed print statement for microphone selection\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmic_list\u001b[49m,index)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mic_list' is not defined"
     ]
    }
   ],
   "source": [
    "def select_microphone():\n",
    "    mic_list = sr.Microphone.list_microphone_names()\n",
    "    return mic_list,\n",
    "    index = 2\n",
    "    # Removed print statement for microphone selection\n",
    "    return index\n",
    "print(mic_list,index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7383e2-3e95-449d-ad3e-2e7d0b64de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_response(text):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio_file:\n",
    "        tts.save(temp_audio_file.name)\n",
    "        temp_file_path = temp_audio_file.name\n",
    "    pygame.mixer.init()\n",
    "    try:\n",
    "        pygame.mixer.music.load(temp_file_path)\n",
    "        pygame.mixer.music.play()\n",
    "\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pygame.time.wait(50)  # Check every 50ms for faster termination\n",
    "\n",
    "    except Exception as e:\n",
    "        st.write(f\"Error playing audio: {e}\")\n",
    "    finally:\n",
    "        pygame.mixer.quit()\n",
    "        if os.path.exists(temp_file_path):\n",
    "            os.remove(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5849671-cf2e-445f-894c-d83b7e4cf786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    # Check if the user asked for the AI's name\n",
    "    if \"what is your name\" in user_input.lower():\n",
    "        return \"I am Amigo, your all-weather conversational companion, just like the bike that you are riding on.\"\n",
    "    \n",
    "    # Handle time and date queries separately\n",
    "    time_date_response = handle_time_date_queries(user_input)\n",
    "    if time_date_response:\n",
    "        return time_date_response\n",
    "\n",
    "    # Check for factual or current event queries\n",
    "    if any(keyword in user_input.lower() for keyword in [ \"who is\", \"when is\", \"where is\", \"current\", \"today\", \"news\",\"capital\",\"Places\"]):\n",
    "        return \"Thank you for your query, but that's out of my scope of training.\"\n",
    "\n",
    "    # Tokenize user input\n",
    "    inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, max_length=50)  # Reduced max length\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    # Generate bot response with reduced max output length\n",
    "    reply_ids = model.generate(inputs['input_ids'], max_length=60, pad_token_id=tokenizer.eos_token_id)  # Reduced response length\n",
    "    \n",
    "    # Decode response with clean-up for tokenization spaces\n",
    "    bot_response = tokenizer.decode(reply_ids[0], skip_special_tokens=True,attention_mask=attention_mask, clean_up_tokenization_spaces=True)\n",
    "    \n",
    "    return bot_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b52963-8392-42d1-a89a-1eee4e38e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_for_wake_word(mic_index):\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone(device_index=mic_index)\n",
    "    \n",
    "    print(\"Waiting for wake word 'Hey Amigo'...\")\n",
    "    while True:\n",
    "        with mic as source:\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=0.5)  # Faster ambient noise adjustment\n",
    "            audio = recognizer.listen(source, timeout=5)  # Timeout added to avoid long waits\n",
    "            \n",
    "        try:\n",
    "            user_input = recognizer.recognize_google(audio)\n",
    "            print(f\"User said: {user_input}\")\n",
    "            if \"hey amigo\" in user_input.lower():\n",
    "                print(\"Wake word detected!\")  # Display wake word detected\n",
    "                return True  # Wake word detected, start conversation\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Error with the Google Speech Recognition service: {e}\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5656b-9c4e-4f5a-8c7e-0e89148c2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amigo_conversational_companion():\n",
    "    mic_index = select_microphone()\n",
    "\n",
    "    # Step 1: Wait for the wake word \"Hey Amigo\"\n",
    "    if listen_for_wake_word(mic_index):\n",
    "        # Step 2: After wake word, greet the user\n",
    "        greeting = \"Hi Hello Namaskara, I am Amigo. How can I help you today?\"\n",
    "        print(f\"Amigo: {greeting}\")\n",
    "        speak_response(greeting)\n",
    "        \n",
    "        # Step 3: Enter conversation loop\n",
    "        while True:\n",
    "            user_input = capture_speech(mic_index)\n",
    "            \n",
    "            if user_input is None:\n",
    "                continue\n",
    "            \n",
    "            # Check if the user wants to exit\n",
    "            if \"exit\" in user_input.lower() or \"goodbye\" in user_input.lower():\n",
    "                farewell_message = \"Goodbye, have a nice day!\"\n",
    "                print(f\"Amigo: {farewell_message}\")\n",
    "                speak_response(farewell_message)\n",
    "                break  # Exit the loop\n",
    "            \n",
    "            # Generate bot response for normal conversation\n",
    "            bot_response = generate_response(user_input)\n",
    "            print(f\"Amigo: {bot_response}\")\n",
    "            \n",
    "            # Speak the bot's response\n",
    "            speak_response(bot_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c14f7-d6b2-45fd-a949-165cab6756a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for wake word 'Hey Amigo'...\n"
     ]
    },
    {
     "ename": "WaitTimeoutError",
     "evalue": "listening timed out while waiting for phrase to start",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWaitTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mamigo_conversational_companion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m, in \u001b[0;36mamigo_conversational_companion\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m mic_index \u001b[38;5;241m=\u001b[39m select_microphone()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 1: Wait for the wake word \"Hey Amigo\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlisten_for_wake_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmic_index\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Step 2: After wake word, greet the user\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     greeting \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi Hello Namaskara, I am Amigo. How can I help you today?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmigo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgreeting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 9\u001b[0m, in \u001b[0;36mlisten_for_wake_word\u001b[1;34m(mic_index)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mic \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[0;32m      8\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Faster ambient noise adjustment\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Timeout added to avoid long waits\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio)\n",
      "File \u001b[1;32m~\\myenv\\lib\\site-packages\\speech_recognition\\__init__.py:489\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    487\u001b[0m elapsed_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m seconds_per_buffer\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    491\u001b[0m buffer \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mread(source\u001b[38;5;241m.\u001b[39mCHUNK)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n",
      "\u001b[1;31mWaitTimeoutError\u001b[0m: listening timed out while waiting for phrase to start"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    amigo_conversational_companion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604cd90-ef90-458a-9ccc-13185e23d1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c43e1-75bc-4747-8b97-021914ba6709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
